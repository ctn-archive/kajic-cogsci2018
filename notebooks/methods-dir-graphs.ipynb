{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import powerlaw\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_angle(v1,v2):\n",
    "    return np.dot(v1,v2)/np.linalg.norm(v1)/np.linalg.norm(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_matrix(vocab, method, model, normed=False):\n",
    "    if method == 'cos':\n",
    "        f_method = cos_angle\n",
    "    else:\n",
    "        f_method = np.dot\n",
    "\n",
    "    mat = np.zeros((len(vocab), len(vocab)))\n",
    "    for i, word1 in enumerate(vocab):\n",
    "        for j in np.arange(i+1, len(vocab)):\n",
    "            word2 = vocab[j]\n",
    "            mat[i,j] = f_method(\n",
    "                model.word_vec(word1, use_norm=normed),\n",
    "                model.word_vec(word2, use_norm=normed))\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing a directed graph from the w2v vectors. This method is introduced in Steyvers & Tenenbaum (2005) and is known as k-nn, since every word will have out-going connections to k other words that are determined as words whose vectors give the highest dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn_edges(mat, vocab, fan_k):\n",
    "    edges = []\n",
    "    matT = mat + mat.T  # get a symmetric matrix\n",
    "    for i, row in enumerate(matT):\n",
    "        word = vocab[i]\n",
    "        k = fan_k[word]\n",
    "        k_assoc = [vocab[assoc] for assoc in np.argsort(row)[::-1][:k]]\n",
    "        edges.extend(list(zip([word]*len(k_assoc), k_assoc)))\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cs-method \n",
    "The method introduced in the Utsumi (2015), the neighbors of a word are computed based on the cumulative similarity \n",
    "ratio:\n",
    "\n",
    "$\\frac{\\Sigma_{w_j \\in V_i^N} \\cos (w_i, w_j)}{\\Sigma_{w_j \\in V} \\cos (w_i, w_j)} > R$\n",
    "\n",
    "It's not entirely clear how they deterimened R_max, but I assume the formula was evaluated for every k, starting with 1 and when it crossed the threshold, that k was was selected. The threshold was probably hand-picked so that it produces <k> as in the association norms.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_k is set to 324 as that was the maximum number of connections for the directed USF networks, but in practice all k's are lower so that number is never reached:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cs_edges(mat, vocab, R_max, max_k=324):\n",
    "    directed_edges = []\n",
    "    ks = []\n",
    "    max_k = 324\n",
    "\n",
    "    matT = mat + mat.T\n",
    "    for i, row in enumerate(matT):\n",
    "        word = vocab[i]\n",
    "\n",
    "        total_sim = np.sum(row)\n",
    "        if total_sim < 0.01:\n",
    "            print(word, total_sim)\n",
    "\n",
    "        for k in range(1, max_k):\n",
    "            k_idx = np.argsort(row)[::-1][:k]\n",
    "            kassoc_sim = np.sum(k_idx)\n",
    "            R = kassoc_sim/total_sim\n",
    "            if R > R_max:\n",
    "                k_assoc = [vocab[assoc] for assoc in k_idx]\n",
    "                directed_edges.extend(list(zip([word]*len(k_assoc), k_assoc)))\n",
    "                break\n",
    "\n",
    "        ks.append(k)\n",
    "    print('Average degree:', np.mean(np.array(ks)))\n",
    "    return directed_edges"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
