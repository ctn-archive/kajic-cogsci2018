{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating undirected and directed word2vec semantic networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load free association network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 'get-graph-norms.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load methods to construct the directed and undirected graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 'methods-dir-graphs.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports for this notebook need to be loaded after imported notebooks above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import powerlaw\n",
    "import networkx as nx\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_w2v = os.path.join(os.pardir, 'data', 'word2vec')\n",
    "path_w2v_raw = os.path.join(os.pardir, 'data', 'word2vec', 'GoogleNews-vectors-negative300.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load word2vec data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might take some time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = KeyedVectors.load_word2vec_format(path_w2v_raw, binary=True)\n",
    "w2v_model.init_sims()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only those words in w2v vocab that also exist in the association network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words not in w2v vocab: 41\n"
     ]
    }
   ],
   "source": [
    "vocab = list(set(fan_vocab) & set(w2v_model.vocab))\n",
    "print('Words not in w2v vocab:', len(fan_vocab)-len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the similarity matrix by computing a dot product between all pairs of vectors in the vocabulary. This is done only for the half of the vocabulary since the dot product is commutative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_inner = get_similarity_matrix(vocab, 'dot', w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_cosine = get_similarity_matrix(vocab, 'cos', w2v_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directed graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. K-nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_edges_knn_dot = get_knn_edges(mat_inner, vocab, fan_dict_k)\n",
    "dir_edges_knn_cos = get_knn_edges(mat_cosine, vocab, fan_dict_k)\n",
    "\n",
    "with open(os.path.join(path_w2v, 'w2v_fan_directed-knn-dot_edgeset.pkl'), 'wb+') as f:\n",
    "    pickle.dump(dir_edges_knn_dot, f)\n",
    "    \n",
    "with open(os.path.join(path_w2v, 'w2v_fan_directed-knn-cos_edgeset.pkl'), 'wb+') as f:\n",
    "    pickle.dump(dir_edges_knn_cos, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. cs-method \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third parameter in `get_cs_edges` is R_max. A few values have been tested to find the one that produces the desired average degree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average degree: 12.52481414506731\n"
     ]
    }
   ],
   "source": [
    "dir_edges_cs_dot = get_cs_edges(mat_inner, vocab, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average degree: 12.595137633112317\n"
     ]
    }
   ],
   "source": [
    "dir_edges_cs_cos = get_cs_edges(mat_cosine, vocab, 76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path_w2v, 'w2v_fan_directed-cs-dot_edgeset.pkl'), 'wb+') as f:\n",
    "    pickle.dump(dir_edges_cs_dot, f)\n",
    "    \n",
    "with open(os.path.join(path_w2v, 'w2v_fan_directed-cs-cos_edgeset.pkl'), 'wb+') as f:\n",
    "    pickle.dump(dir_edges_cs_cos, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undirected graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The range for the thresholds has been determined by observing the number of edges in resulting graph (post-thresholding) that roughly corresponds to the number of edges in the association network. \n",
    "Graphs that are \"close\" to the picked one are also saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity: cos\n",
      "tau: 0.37, m: 60147, k: 24.42\n",
      "tau: 0.38, m: 52317, k: 21.35\n",
      "tau: 0.39, m: 45527, k: 18.67\n",
      "similarity: dot\n",
      "tau: 4.19, m: 44981, k: 22.32\n",
      "tau: 4.20, m: 44442, k: 22.10\n",
      "tau: 4.21, m: 43886, k: 21.85\n"
     ]
    }
   ],
   "source": [
    "undirected_settings = [\n",
    "    (np.arange(0.37, 0.39, .01), mat_cosine, 'cos'),\n",
    "    (np.arange(4.19, 4.22, .01), mat_inner, 'dot')]\n",
    "\n",
    "for th, mat, method in undirected_settings:\n",
    "    print('similarity:', method)\n",
    "    for t in th:\n",
    "        edges = []\n",
    "        x, y = np.where(mat>=t)\n",
    "        for w1, w2 in zip(x, y):\n",
    "            edge = (vocab[w1], vocab[w2], mat[w1,w2])\n",
    "            edges.append(edge)\n",
    "\n",
    "        g_un = nx.Graph()\n",
    "        g_un.add_weighted_edges_from(edges)\n",
    "\n",
    "        str_print = \"tau: {:.2f}, m: {}, k: {:.2f}\".format(\n",
    "            t, len(edges), 2*nx.number_of_edges(g_un)/nx.number_of_nodes(g_un))\n",
    "        print(str_print)\n",
    "\n",
    "        tau = '%.2f'%t\n",
    "        save_path = 'w2v_fan_%.2f_%s_edgeset.pkl'%(t, method)\n",
    "\n",
    "        with open(os.path.join(path_w2v, save_path), 'wb+') as f:\n",
    "            pickle.dump(edges, f) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
